URSentinel: Project Architecture & Technical Documentation(Simplified Version)This document outlines the complete technical structure for URSentinel, a web-based Universal Robot log file visualizer and diagnostics suite. This version is a streamlined "stateless" app that does not require user tracking.1. Core Technology StackFrontend: Next.js (or React with React Router)UI Components: shadcn/uiCharting: recharts (for 2D) & plotly.js (for 3D)Backend: SupabaseDatabase: Supabase PostgresFile Storage: Supabase StorageServerless Logic: Supabase Edge FunctionsCSV Parsing: papaparse (will be used inside the Edge Function)2. Authentication FlowNo authentication is required. This app will be fully public and stateless. Each analysis is session-specific, and no history is saved.3. Supabase Database SchemaWe need one primary table to store the results of our analysis. Since we are not tracking users, data in this table will be temporary. We can set up a simple policy to allow any (anon) user to create and read rows.Table: analysis_resultsThis table stores the processed results. The app is fast because it only ever fetches this lightweight JSON.-- Main table to hold all processed analysis data
CREATE TABLE public.analysis_results (
  id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- Info about the original file
  file_name TEXT,
  storage_path TEXT, -- Full path in Supabase Storage
  total_run_time_sec FLOAT,

  -- === 1. At-a-Glance KPIs ===
  kpi_max_following_error JSONB, -- { "value": 0.61, "joint": 3, "time": 749.2 }
  kpi_peak_current JSONB,        -- { "value": 5.2, "joint": 2, "time": 751.4 }
  kpi_peak_temp JSONB,           -- { "value": 41.5, "joint": 2, "time": 810.3 }
  kpi_peak_tcp_force JSONB,      -- { "value": 12.5, "axis": "z", "time": 751.5 }

  -- === 2. Anomaly Log ===
  anomalies JSONB,

  -- === 3. Chart Data (Full Series) ===
  ts_tcp_path JSONB,             -- Array of [x, y, z] for 3D plot
  ts_tcp_orientation JSONB,    -- { time: [], rx: [], ry: [], rz: [] }
  ts_following_error JSONB,    -- { time: [], j1: [], j2: [], ... }
  ts_target_position JSONB,
  ts_actual_position JSONB,
  ts_tcp_force JSONB,            -- { time: [], fx: [], fy: [], fz: [] }
  ts_tcp_torque JSONB,           -- { time: [], tx: [], ty: [], tz: [] }
  ts_target_torque JSONB,
  ts_target_acceleration JSONB,
  ts_actual_current JSONB,
  ts_target_current JSONB,
  ts_control_current JSONB,
  ts_joint_temps JSONB
);

-- === 4. Row Level Security (RLS) ===
-- We enable RLS but set a public-facing policy.
ALTER TABLE public.analysis_results ENABLE ROW LEVEL SECURITY;

-- Policy: Anyone can create and read any analysis result.
-- This is fine for a stateless demo project.
CREATE POLICY "Enable public read and write access"
ON public.analysis_results
FOR ALL
USING (true)
WITH CHECK (true);

-- Optional: For a real-world app, you might add a cron job
-- to delete rows older than 24 hours to save space.
4. Application Flow (User Journey)User lands on / (Hero Page): User sees the upload prompt.User Uploads .csv: The file is sent to Supabase Storage.Function Invoked: On successful upload, the client (browser) calls the analyze-log Edge Function, passing the storage_path and file_name.const { data, error } = await supabase.functions.invoke('analyze-log', {
  body: { 
    storagePath: 'logs/my-file.csv',
    fileName: 'my-file.csv'
  }
});
// data.analysisId will be the ID of the new row
Edge Function Runs: The analyze-log function (see section 5):Downloads the file from Storage.Parses the entire CSV.Calculates all KPIs and time-series data.Generates the Anomaly Log.Saves all this data as a single new row in the analysis_results table.Returns the id of the new row.Redirect: The client receives the new analysisId and redirects the user: router.push('/dashboard/' + data.analysisId).User Views Data: The DashboardPage (/dashboard/[id]) and AnalysisPage (/analysis/[id])Fetch the single row from analysis_results where id matches the URL.They are "dumb" pages: they just get the pre-processed JSON data (e.g., data.ts_following_error) and pass it to the charts.5. Supabase Edge FunctionsThis is the "brain" of the app. We'll create one main function.Directory Structure:supabase/
  functions/
    _shared/
      supabase-client.ts
      column-indices.ts
    analyze-log/
      index.ts
supabase/functions/_shared/supabase-client.ts(Handles creating a simple anon Supabase client)import { createClient } from "[https://esm.sh/@supabase/supabase-js@2](https://esm.sh/@supabase/supabase-js@2)";

// This client uses the ANON_KEY and is fine for public operations.
export const supabase = createClient(
  Deno.env.get("SUPABASE_URL") ?? "",
  Deno.env.get("SUPABASE_ANON_KEY") ?? ""
);
supabase/functions/_shared/column-indices.ts(This is our "key" based on your header file. It makes the main code readable.)// Based on ur5testresult_header.xlsx
export const COL_TIME = 0;

// Target vs Actual Position (Kinematics)
export const T_POS = [1, 2, 3, 4, 5, 6];
export const A_POS = [7, 8, 9, 10, 11, 12];

// Target vs Actual Velocity (Kinematics)
export const T_VEL = [13, 14, 15, 16, 17, 18];
export const A_VEL = [19, 20, 21, 22, 23, 24];

// Target vs Actual Current (Electrical)
export const T_CUR = [25, 26, 27, 28, 29, 30];
export const A_CUR = [31, 32, 33, 34, 35, 36];

// Target Acceleration (Dynamics)
export const T_ACC = [37, 38, 39, 40, 41, 42];

// Target Torque (Dynamics)
export const T_TORQUE = [43, 44, 45, 46, 47, 48];

// Control Current (Electrical)
export const C_CUR = [49, 50, 51, 52, 53, 54];

// TCP Coordinates (Kinematics)
export const TCP_POS = [55, 56, 57]; // x, y, z
export const TCP_ORIENT = [58, 59, 60]; // rx, ry, rz

// TCP Force (Dynamics)
export const TCP_FORCE = [61, 62, 63]; // Fx, Fy, Fz
export const TCP_TORQUE = [64, 65, 66]; // Tx, Ty, Tz

// Joint Temps (Diagnostics)
export const TEMPS = [67, 68, 69, 70, 71, 72];
supabase/functions/analyze-log/index.ts(The main event. This function is complex, but it does all the work.)import "jsr:@supabase/functions-js/edge-runtime.d.ts";
import { parse } from "[https://esm.sh/papaparse@5.4.1](https://esm.sh/papaparse@5.4.1)";
import { supabase } from "../_shared/supabase-client.ts"; // Use the simple anon client
import * as C from "../_shared/column-indices.ts";

// --- Anomaly Thresholds (Configurable) ---
const ERROR_THRESHOLD_RAD = 0.5;
const CURRENT_THRESHOLD_AMPS = 5.0;
const TEMP_THRESHOLD_CELSIUS = 40.0;
const FORCE_THRESHOLD_NEWTONS = 10.0;

// --- Data Sampling (for charts) ---
const MAX_CHART_POINTS = 1000;

Deno.serve(async (req) => {
  try {
    const { storagePath, fileName } = await req.json();

    // 1. Download file from Storage
    const { data: fileData, error: storageError } = await supabase
      .storage
      .from("logs") // NOTE: Assumes your bucket is named 'logs'
      .download(storagePath);
    if (storageError) throw storageError;

    const csvText = await fileData.text();

    // 2. Parse CSV text
    const parseResult = parse(csvText, {
      skipEmptyLines: true,
      dynamicTyping: true, // Converts numbers automatically
    });

    const rows: (number[])[] = parseResult.data.slice(1); // Skip header row
    const rowCount = rows.length;
    if (rowCount === 0) throw new Error("No data rows found in CSV.");

    // --- 3. Initialize Data Structures ---

    // KPIs
    let kpi_max_following_error = { value: 0, joint: -1, time: 0 };
    let kpi_peak_current = { value: 0, joint: -1, time: 0 };
    let kpi_peak_temp = { value: 0, joint: -1, time: 0 };
    let kpi_peak_tcp_force = { value: 0, axis: "x", time: 0 };

    // Anomaly Log
    const anomalies: any[] = [];

    // Time Series (omitted for brevity, same as previous version)
    const ts_tcp_path = [];
    const ts_tcp_orientation = { time: [], rx: [], ry: [], rz: [] };
    const ts_following_error = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_target_position = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_actual_position = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_tcp_force = { time: [], fx: [], fy: [], fz: [] };
    const ts_tcp_torque = { time: [], tx: [], ty: [], tz: [] };
    const ts_target_torque = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_target_acceleration = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_actual_current = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_target_current = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_control_current = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };
    const ts_joint_temps = { time: [], j1: [], j2: [], j3: [], j4: [], j5: [], j6: [] };


    // --- 4. Process All Rows ---
    const step = Math.max(1, Math.floor(rowCount / MAX_CHART_POINTS));
    
    for (let i = 0; i < rowCount; i++) {
      const row = rows[i];
      if (!row || row.length < 73) continue; // Skip bad rows
      
      const time = row[C.COL_TIME];

      // --- Process KPIs and Anomalies (Run on every row) ---
      
      // Check Following Error
      for (let j = 0; j < 6; j++) {
        const error = Math.abs(row[C.A_POS[j]] - row[C.T_POS[j]]);
        if (error > kpi_max_following_error.value) {
          kpi_max_following_error = { value: error, joint: j + 1, time: time };
        }
        if (error > ERROR_THRESHOLD_RAD && i % step === 0) { // Only log anomalies on sampled steps to avoid spam
          anomalies.push({ time, type: "High Following Error", joint: j + 1, details: `Error was ${error.toFixed(2)} rad` });
        }
      }

      // Check Current
      for (let j = 0; j < 6; j++) {
        const current = Math.abs(row[C.A_CUR[j]]);
        if (current > kpi_peak_current.value) {
          kpi_peak_current = { value: current, joint: j + 1, time: time };
        }
        if (current > CURRENT_THRESHOLD_AMPS && i % step === 0) {
          anomalies.push({ time, type: "Current Spike", joint: j + 1, details: `Current was ${current.toFixed(2)} A` });
        }
      }

      // Check Temps
      for (let j = 0; j < 6; j++) {
        const temp = row[C.TEMPS[j]];
        if (temp > kpi_peak_temp.value) {
          kpi_peak_temp = { value: temp, joint: j + 1, time: time };
        }
        if (temp > TEMP_THRESHOLD_CELSIUS && i % step === 0) {
          anomalies.push({ time, type: "High Temperature", joint: j + 1, details: `Temp was ${temp.toFixed(1)} Â°C` });
        }
      }

      // Check TCP Force
      const forces = [Math.abs(row[C.TCP_FORCE[0]]), Math.abs(row[C.TCP_FORCE[1]]), Math.abs(row[C.TCP_FORCE[2]])];
      const axes = ["x", "y", "z"];
      for (let j = 0; j < 3; j++) {
        if (forces[j] > kpi_peak_tcp_force.value) {
          kpi_peak_tcp_force = { value: forces[j], axis: axes[j], time: time };
        }
        if (forces[j] > FORCE_THRESHOLD_NEWTONS && i % step === 0) {
          anomalies.push({ time, type: "TCP Force Event", joint: null, details: `Force on ${axes[j]}-axis was ${forces[j].toFixed(1)} N` });
        }
      }

      // --- Process Time Series Data (Run only on sampled rows) ---
      if (i % step === 0) {
        // 3D Path
        ts_tcp_path.push([row[C.TCP_POS[0]], row[C.TCP_POS[1]], row[C.TCP_POS[2]]]);
        
        // Feed data into each time series object
        ts_tcp_orientation.time.push(time);
        ts_tcp_orientation.rx.push(row[C.TCP_ORIENT[0]]);
        ts_tcp_orientation.ry.push(row[C.TCP_ORIENT[1]]);
        ts_tcp_orientation.rz.push(row[C.TCP_ORIENT[2]]);

        ts_tcp_force.time.push(time);
        ts_tcp_force.fx.push(row[C.TCP_FORCE[0]]);
        ts_tcp_force.fy.push(row[C.TCP_FORCE[1]]);
        ts_tcp_force.fz.push(row[C.TCP_FORCE[2]]);
        
        ts_tcp_torque.time.push(time);
        ts_tcp_torque.tx.push(row[C.TCP_TORQUE[0]]);
        ts_tcp_torque.ty.push(row[C.TCP_TORQUE[1]]);
        ts_tcp_torque.tz.push(row[C.TCP_TORQUE[2]]);
        
        // Per-joint data
        for (let j = 0; j < 6; j++) {
          const jointKey = `j${j+1}` as keyof typeof ts_following_error;
          
          if (!ts_following_error[jointKey]) {
            // Initialize arrays for each joint
            ts_following_error[jointKey] = [];
            ts_target_position[jointKey] = [];
            ts_actual_position[jointKey] = [];
            ts_target_torque[jointKey] = [];
            ts_target_acceleration[jointKey] = [];
            ts_actual_current[jointKey] = [];
            ts_target_current[jointKey] = [];
            ts_control_current[jointKey] = [];
            ts_joint_temps[jointKey] = [];
          }

          ts_following_error[jointKey].push(row[C.A_POS[j]] - row[C.T_POS[j]]);
          ts_target_position[jointKey].push(row[C.T_POS[j]]);
          ts_actual_position[jointKey].push(row[C.A_POS[j]]);
          ts_target_torque[jointKey].push(row[C.T_TORQUE[j]]);
          ts_target_acceleration[jointKey].push(row[C.T_ACC[j]]);
          ts_actual_current[jointKey].push(row[C.A_CUR[j]]);
          ts_target_current[jointKey].push(row[C.T_CUR[j]]);
          ts_control_current[jointKey].push(row[C.C_CUR[j]]);
          ts_joint_temps[jointKey].push(row[C.TEMPS[j]]);
        }
        // Add time to all joint-based objects
        ts_following_error.time.push(time);
        ts_target_position.time.push(time);
        ts_actual_position.time.push(time);
        ts_target_torque.time.push(time);
        ts_target_acceleration.time.push(time);
        ts_actual_current.time.push(time);
        ts_target_current.time.push(time);
        ts_control_current.time.push(time);
        ts_joint_temps.time.push(time);
      }
    }

    // --- 5. Create Final Database Row ---
    const analysisData = {
      // No user_id
      file_name: fileName,
      storage_path: storagePath,
      total_run_time_sec: rows[rowCount - 1][C.COL_TIME] - rows[0][C.COL_TIME],

      kpi_max_following_error,
      kpi_peak_current,
      kpi_peak_temp,
      kpi_peak_tcp_force,
      
      anomalies,
      
      // All the bulky time-series data
      ts_tcp_path,
      ts_tcp_orientation,
      ts_following_error,
      ts_target_position,
      ts_actual_position,
      ts_tcp_force,
      ts_tcp_torque,
      ts_target_torque,
      ts_target_acceleration,
      ts_actual_current,
      ts_target_current,
      ts_control_current,
      ts_joint_temps,
    };

    // --- 6. Insert into Database ---
    const { data: newAnalysis, error: dbError } = await supabase
      .from("analysis_results")
      .insert(analysisData)
      .select("id")
      .single();

    if (dbError) throw dbError;

    // --- 7. Return the ID of the new analysis ---
    return new Response(
      JSON.stringify({ analysisId: newAnalysis.id, message: "Analysis complete!" }),
      { headers: { "Content-Type": "application/json" } }
    );

  } catch (err) {
    console.error("Error in analyze-log function:", err);
    return new Response(
      JSON.stringify({ error: err.message }),
      { status: 500, headers: { "Content-Type": "application/json" } }
    );
  }
});
